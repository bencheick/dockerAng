m4 - Securing Your Docker Registry
Our Docker Registry is indeed running and patiently waiting for our clients to start pulling and pushing images, but there is a bit of a problem. Unless you happen to be on the same host machine on which the registry is installed, we won't have access. That's because Docker Registry only accepts activity coming over encrypted connections. No encrypted connection? No pulling and pushing for you.
Let me show you how it works...or, actually, how it doesn't work. I'll use curl to list the images as we did earlier, but from a remote machine with Docker installed. Then I'll try to pull an image down to the machine. It's no-go. The registry was expecting an HTTPS request. 
Why is Docker Registry built this way? It's all about elementary security. Even if you're only planning on sharing the registry among local clients, all unencrypted traffic between any two hosts will be plainly visible to man-in-the-middle attackers. If you've got anything sensitive built into your images - and most of the time you probably will - then that data will very likely soon be part of the public record. 
Ok. So to make our registry at all useful, we'll have to find a way to enable proper encryption. 
In this module I'm going to explain how to use the certificates issued by a recognized Certificate Authority to encrypt registry traffic moving back and forth between your clients. In fact, I'll show you three different ways to apply certificates, each with its own advantages and disadvantages. To make it easier for you to try out encryption within test environments, I'll also demonstrate using self-signed certificates. Deploying self-signed certs will take a bit of extra work, but it's not nearly as hard as you might, at first, imagine.
Finally, we'll talk about a second important aspect of image security: configuring login authentication for your Docker Registry.
Let's get started.

To make this work, you'll need to have a certificate for your domain issued by a Certificate Authority. This can be the same certificate you use for your website traffic, so the odds are that this won't require any extra work on your side. If the domain you're planning to use doesn't already have a certificate, you can now request free certs from Let's Encrypt. Not sure how that works? Well, I just happen to have a course here on Pluralsight that can help: Linux Encryption Security.
Once you've got your cert, you could copy the .crt and .key files you're given to their own directory. You can also leave them where they are and point to their location in the next step. Your choice. I will note that, if the package you've been sent by the CA includes an intermediary file (usually ending with .pem), then you'll need to combine the .crt and .pem into a single .crt file. 
With your cert files in place, you're nearly there. If you're running Docker Registry using the registry container, then you can incorporate the certs into your run command like this. 
Let's work through the syntax. We're already familiar with docker run and -d (to detach from the container at start) and -p (to specify the access port). "restart-always" tells the system to launch the Registry on reboot, and --name tells us the name to use when identifying the running container. Now we get to the new material. -v defines a volume, which can really be any location containing data you'd like to include in the container. In this case, the location will be based on the "present work directory" and, specifically include any files in the directory called certs. You can obviously point to whichever directory where your cert files are currently living.
-e refers to environment values. These two lines point directly to the .crt and .key certificate files. The last line is the instruction to launch the image called "registry." This assumes, of course, that the name of your domain is stuff.com - something that's highly unlikely, but works well as an example. That's it. Once the container loads, both the server and its clients will automatically be using the certificate to encrypt requests and responses for both pulls and pushes.
You can also package your cert files into an image using a dockerfile. This example will use the registry image as its base, add the certs directory and its contents to /home/ on the container, and set the certificate and key environment variables to use our keys. It will also open port 5000.
There's one more way to use certificates, and this one will work for both container-based and installed registries. Docker Registry configuration can be controlled by a file called config.yml that's kept in the /etc/docker/registry/ directory. As you can see, the file is divided into sections like "storage" and "http". I'm going to add a subsection to http called tls (which, by the way, stands for Transport Layer Security). Then I'll add a value for "certificate", which will be pointed to stuff.crt file within a certs directory that doesn't yet exist, and another value for "key" aimed at a .key file in the same new directory. Right now I'm just doing this to show you how it's done, but I will actually use this configuration in the next clip. 
If you're working with an installed registry, then all that's left to do is restart the service. If you're running the registry from a container, then you'll need to add the file as a volume along with the run command.

Ok. We're finally ready to try this out. But I'm going to do it using a self-signed certificate, so I'll have to jump through a few hoops to properly set up the lab. Even though using self-signed certs is definitely not normally recommended, it will have two benefits in our case: one, it's something I can easily demonstrate even in my local test environment and, two, it's a great way to help you visualize how the certificate process actually works.
First, I'm going to use local DNS settings to enable the use of a stuff.com domain for machines on my local network. I will then generate a self-signed certificate for stuff.com and install the cert files on my Docker Registry host. Finally, I'll copy the .crt file from my Registry host to each a Docker client I want to have access to the registry. 
Let's get going. On Linux machines, requests for network domains are first sent to a local file called "hosts" that lives in the /etc/ directory. If there's an entry in hosts matching the requested domain name, then the request will be forwarded to the associated IP address. If there are no matching entries on a local database, then the request will be sent out to public internet DNS databases. What I'm going to do is add an entry to the hosts file on this machine that I'd like to use as a Docker client. The IP I'm using belongs to my Docker Registry server. I would normally do this on all the machines in my local network to which I'd like to give domain name access...including the registry server itself. 
Now I'll move over to the machine that has Docker Registry installed - the server. I'll create a directory beneath my user's home called certs. I'll then run this openssl command to create cert key files and save them to the certs directory. If you want to learn more about what this command is actually doing, check out my Linux Encryption Security course. But what's important for us is that I've named the crt and key files stuff. You will be taken through an interview where your domain profile is established. Since we're self-signing here, the only value that really matters is the final question about the Common Name we're giving the domain. That one has to be accurate, and will be stuff.com in my case. 
You'll remember how I added cert file values to the config.yml file earlier. Now I'll just take a quick second look to make sure they match the files I've actually created. Looks good. To make these changes take effect, I'll restart the docker-registry server. Don't worry about the "unable to resolve host docker-server" message, that's just because I've confused the poor system by changing my command line prompt to make it more obvious which machine is which.
The last thing I need to do on the server is securely copy my .crt file to my client. scp is a great tool for this purpose. 
Let's move back to the client. I'll rename the stuff.crt file to ca.crt, and then create a directory tree beneath /etc/docker starting with certs.d, with stuff.com:5000 beneath it. I'll need to get admin powers to do this through sudo, since it's in the /etc/ hierarchy. Two more steps. The first is copying the ca.crt file to the new stuff.com:5000 directory, and the second is restarting Docker (not docker-registry, since our client machine isn't running DR).
We can test the whole mess out by seeing if we can pull an image from the remote registry...success!
Before you get too carried away with your well-earned victory celebrations, I should tell you that setting up encryption will have an effect on the way you access Docker resources on your registry host. For instance, using curl to get a list of images the way we did in the previous module will no longer work. However, adding https:// to the URL should help...unless, that is, you're using a self-signed certificate as I am, rather than one from a Certificate Authority. As you can see from the error message provided by curl, if you're absolutely desperate, you can still make it work by adding the --insecure flag. Just remember that the information will be moving through the network without any encryption at all.

Having used encryption to secure the transfer of images into and out of our Docker Registry, we've made it much more likely that our data won't be intercepted and abused. But how do we know that the users pushing and pulling into the registry are our users? How do we know the person on the remote machine didn't get there illegally? 
The most obvious first step to solving that problem is to enforce password-based authentication. And here too, Docker's got you covered. Relying on the certificate files we're already using, we'll generate user accounts and passwords and configure DR to require a login before anyone can access the registry. 
I'll begin by creating a directory called auth within my user's home directory on the DR server. Next. I'll run the DR registry image as a container for the express purpose of adding the a username and password combination to a file called htpasswd in the auth directory. I use two right arrows (>>) so the operation will append the new data to any records that might already exist. As it turns out, there's no such file yet, but this is a good habit to get into all the same (using one right arrow will overwrite all the current contents of the file with the new text - something you usually won't want to happen). 
This will (if necessary) pull the registry image from Docker Hub and populate the htpasswd file with only the username and an encrypted version of the password I specified. There are, of course, other ways to generate htpasswd files - in particular, Apache's htpasswd program from the apache2-utils package. But this is a Docker course, right?
Now we'll need to tell DR about the new password file by once again editing the config.yml file. I'll add a new section called auth, and add these three lines. Make sure you provide the correct path to the htpasswd file we just generated on the "path" line. Since we've edited the config.yml file, we'll need to restart DR before the new settings will take effect.
I'll head over to a Docker client and try pushing a local image to the registry. Docker images tells me that there's an Alpine Linux image in our local collection. Docker tag will address it to our stuff.com server. I'll try docker push, but remember, we haven't provided the basic auth credentials. Well I'll be! It didn't work. We can fix that pretty fast. We'll use docker login, but rather than logging into my Docker Hub account, I'll specify the stuff.com server, and, when prompted enter my login credentials. Once that's done, I'm able to push images to my little heart's content.

It's time for some review. 
We learned how Docker Registry expects remote requests to use TLS encryption, which can be provided either through the certificate files issued by a recognized Certificate Authority, or through self-signed certificates generated locally. You tell DR about your cert files in any one of three ways: when running a container, through the -e (environment) argument, as part of a dockerfile configuration, or through the config.yml file that can be added to a container as a volume at run time.
If you decide to use a self-signed certificate, you'll need to copy the .crt file to each client that will be connecting. The .crt file should be renamed ca.crt and saved to the /etc/docker/certs.d/stuff.com:5000/ directory. And finally, we learned how to set up password authentication to our DR server through generating an htpasswd file and adding the htpasswd configuration to the config.yml file. 
Up next: a look at a few more image management tools.

